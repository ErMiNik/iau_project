{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 EDA and data preprocessing \t(5b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ako prve opiseme tento dataset. Dataset obsahuje snimky pluc. Tieto snimky su roztriedene na zaklade chorob na 3 kategorie\n",
    "# Plucia cloveka s Covid-19, Viral Pneumonia a normálne zdravé plucia.\n",
    "\n",
    "# toto je opis z konkretnej stranky z kade boli data stianuté.\n",
    "\n",
    "# Content\n",
    "# It is a simple directory structure branched into test and train and further branched into the respective 3 classes which contains the images.\n",
    "\n",
    "\n",
    "# About this directory\n",
    "# It contains around 137 cleaned images of COVID-19 and 317 in total \n",
    "# containing Viral Pneumonia and Normal Chest X-Rays structured into the test and train directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importy\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "folder = Path(\"./Covid19-dataset\")\n",
    "\n",
    "\n",
    "classes = [\"Covid\", \"Viral Pneumonia\", \"Normal\"]\n",
    "train_dir_path = folder / \"train\"\n",
    "test_dir_path = folder / \"test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (A-4b)\tEDA a data preprocessing pre Vami vybrané charakteristiky z datasetu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Najprv preskumanim struktury datasetu\n",
    "\n",
    "# vypis velkosti konkretnych dat pre kazdu classu\n",
    "for cls in classes:\n",
    "    print(f\"{cls} - Train Images: {len(os.listdir(train_dir_path/cls))}\")\n",
    "    print(f\"{cls} - Test Images: {len(os.listdir(test_dir_path/cls))}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dalej si vypiseme a zobrazime graficky rozsah\n",
    "# rozlisenia (pocet pixelov) pre classy\n",
    "from PIL import Image\n",
    "\n",
    "def visualize_resolutions(class_name: str, data_path: str):\n",
    "    class_path = os.path.join(data_path, class_name)\n",
    "    images_lst = os.listdir(class_path)\n",
    "    \n",
    "    resolutions = []\n",
    "\n",
    "    # Iterate through images and collect resolutions\n",
    "    for image_name in images_lst:\n",
    "        image_path = os.path.join(class_path, image_name)\n",
    "        try:\n",
    "            # Load the image\n",
    "            image = Image.open(image_path)\n",
    "            # Get the resolution\n",
    "            width, height = image.size\n",
    "            resolutions.append((width, height))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_name}: {e}\")\n",
    "    \n",
    "    # Calculate resolution ranges\n",
    "    widths = [res[0] for res in resolutions]\n",
    "    heights = [res[1] for res in resolutions]\n",
    "    \n",
    "    width_range = (min(widths), max(widths))\n",
    "    height_range = (min(heights), max(heights))\n",
    "    \n",
    "    print(f\"Width range: {width_range}\")\n",
    "    print(f\"Height range: {height_range}\")\n",
    "    \n",
    "    # Visualize resolution distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Scatter plot for individual resolutions\n",
    "    plt.scatter(widths, heights, alpha=0.7, label=\"Image Resolutions\")\n",
    "    plt.xlabel(\"Width\")\n",
    "    plt.ylabel(\"Height\")\n",
    "    plt.title(f\"Resolution Distribution for {class_name}\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    # Histogram of widths and heights\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(widths, bins=20, alpha=0.7, color='blue', label=\"Widths\")\n",
    "    plt.xlabel(\"Width\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Width Distribution\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(heights, bins=20, alpha=0.7, color='green', label=\"Heights\")\n",
    "    plt.xlabel(\"Height\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Height Distribution\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls in classes:\n",
    "    visualize_resolutions(cls, train_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "# definujeme si funkciu ktora vizualizuje nahodne samples obrazkov\n",
    "# zo zadanej classy\n",
    "def visualize_samples(class_name: str, data_path: str, sample_size: int):\n",
    "    class_path = data_path/class_name\n",
    "    images_lst = os.listdir(class_path)\n",
    "    images_sample = sample(images_lst, sample_size)\n",
    "    plt.figure(figsize=(10, sample_size))\n",
    "    for i, image_name in enumerate(images_sample):\n",
    "        img_path = class_path/image_name\n",
    "        img_arr = plt.imread(img_path)\n",
    "        plt.subplot(1, sample_size, i + 1)\n",
    "        plt.imshow(img_arr, cmap=\"gray\")\n",
    "        plt.title(class_name + \" \" + image_name)\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls in classes:\n",
    "    visualize_samples(cls, train_dir_path, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_grayscale(image_path):\n",
    "    # Load the image\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    img_array = np.array(image)\n",
    "    \n",
    "    # Check if it's an RGB image\n",
    "    if image.mode == \"RGB\":\n",
    "        # Compare all three channels (R, G, B) for equality\n",
    "        if np.all(img_array[:, :, 0] == img_array[:, :, 1]) and np.all(img_array[:, :, 1] == img_array[:, :, 2]):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# na sample snimkoch mozme vidiet ze su obrazky \n",
    "# v grayscale, chceme sa ale presvedcit ci su \n",
    "# takehoto typu vsetky obrazky v datasete, \n",
    "# preto prejdeme celym datasetom a ziskame \"rgb\" mode\n",
    "# alebo \"L\" mode ktore oznacuje grayscale\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def print_color_modes(class_name: str, data_path:str):\n",
    "    class_path = data_path/class_name\n",
    "    images_lst = os.listdir(class_path)\n",
    "    color_modes = []\n",
    "    for image_name in images_lst:\n",
    "        try:\n",
    "            image = Image.open(class_path/image_name)\n",
    "            if is_grayscale(class_path/image_name):\n",
    "                color_modes.append(\"L\")\n",
    "            else:\n",
    "                color_modes.append(image.mode)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_name}: {e}\")\n",
    "\n",
    "    mode_counts = Counter(color_modes)\n",
    "    print(f\"Color modes in {class_name} class\")\n",
    "    for mode, count in mode_counts.items():\n",
    "        print(f\"{mode}: {count}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls in classes:\n",
    "    print_color_modes(cls, train_dir_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st output:\n",
    "# Color modes in Covid class\n",
    "# RGB: 69\n",
    "# RGBA: 5\n",
    "# L: 37\n",
    "\n",
    "# Color modes in Viral Pneumonia class\n",
    "# RGB: 70\n",
    "\n",
    "# Color modes in Normal class\n",
    "# RGB: 70\n",
    "\n",
    "# mozme vidiet ze vacsia cast snimkov su ulozene v RGB mode\n",
    "# presnejsie 209/251, predtym ako vsetky convertujeme na grayscale\n",
    "# sa ujistime ze RGB hodnoty pri RGB zakodovanych obrazkoch\n",
    "# su hodnoty, co by vypocedalo ze su grayscale, aj ked su v RGB mode\n",
    "\n",
    "# pridame funkciu a upravime povodnu funkciu na detekciu modov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd output:\n",
    "# Color modes in Covid class\n",
    "# L: 102\n",
    "# RGBA: 5\n",
    "# RGB: 4\n",
    "\n",
    "# Color modes in Viral Pneumonia class\n",
    "# L: 70\n",
    "\n",
    "# Color modes in Normal class\n",
    "# L: 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z 2. iteracie vysledkov mozme vidiet ze vacsina obrazkov je grayscale\n",
    "# a preto je bezpecne prehlasit ze mozme zmenit celemu datasetu mode na gray scale\n",
    "# pre konzistenciu, alebo s nim narabat tak, ze su vsetky obrazky rovnakeho typu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# este skontrolujeme v akom formate su snimky ulozene\n",
    "\n",
    "def print_image_formats(class_name: str, data_path:str):\n",
    "    class_path = data_path/class_name\n",
    "    images_lst = os.listdir(class_path)\n",
    "    formats = []\n",
    "    for image_name in images_lst:\n",
    "        \n",
    "        formats.append(image_name.split(\".\")[-1])\n",
    "    \n",
    "    format_counts = Counter(formats)\n",
    "    print(f\"Image formats in {class_name} class\")\n",
    "    for img_format, count in format_counts.items():\n",
    "        print(f\"{img_format}: {count}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls in classes:\n",
    "    print_image_formats(cls, train_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mozme vidiet ze nemame konzistentne file formaty,\n",
    "# co by nemuselo, ale mohlo v buducnosti vadit v nasom workflowe\n",
    "# preto v jednej funkcii vsetky obrazky zmenine do graysclae modu \"L\"\n",
    "# a taktiez ich convertujeme na konzistentny rovnaky\n",
    "# file format\n",
    "\n",
    "\n",
    "def convert_to_grayscale_and_save(source_folder, target_folder, target_format=\"JPEG\"):\n",
    "\n",
    "    os.makedirs(target_folder, exist_ok=True)\n",
    "    \n",
    "    for image_name in os.listdir(source_folder):\n",
    "        try:\n",
    "            # Define source and target paths\n",
    "            image_path = source_folder / image_name\n",
    "            new_name = os.path.splitext(image_name)[0] + \".jpg\"\n",
    "            target_path = target_folder / new_name\n",
    "            \n",
    "            # Open the image\n",
    "            image = Image.open(image_path)\n",
    "            \n",
    "            # Convert to grayscale\n",
    "            grayscale_image = image.convert(\"L\")\n",
    "            \n",
    "            # Save in the target format\n",
    "            grayscale_image.save(target_path, target_format)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_train = Path(\"./Covid_preprocess/train/\")\n",
    "for cls in classes:\n",
    "    convert_to_grayscale_and_save(train_dir_path/cls, save_path_train/cls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_test = Path(\"./Covid_preprocess/test/\")\n",
    "for cls in classes:\n",
    "    convert_to_grayscale_and_save(test_dir_path/cls, save_path_test/cls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hlavne vystupy a pozorovania z EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Dataset ma 3 triedy snimkov pluc (Covid-19, Viral Pneumonia, Normal)\n",
    "2. Konkrétne počty tried sú:\n",
    "    1. 137 - Covid-19\n",
    "    2. 317 - Pneumonia + Normal\n",
    "    - Data sú už predom rozdelené na trénovacie (~79%) a testovacie ~(21%)\n",
    "3. Pôvodné snimky boli vsetky už čiernobiele, všetky sme preiterovali a zmenili ich mode na \"L\" grayscale pre konzistentnosť ( Toto je už čast preprocesingu [hups?])\n",
    "4. Snímky boli uložené v rôzných file formátoch, pre konzistentnosť sme ich všetky uložili do jednotného formátu .jpg\n",
    "5. Na grafoch a vo výpisoch môžme vidieť aj diverzitu v rozlíšeniach jednotlivých skupín snímkov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Časť preprocesingu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V následujúcej časti budeme vykonávať následujúce metódy preprocesingu. (na poradí datých techník záleží).\n",
    "1. Grayscaling (táto časť bola už vykonaná v rámci EDA)\n",
    "2. Redukcia Šumu - (Gaussian Blur alebo Median Filtering), zabráni zosilnenie šumu v procese ostrenia\n",
    "3. Zaostrovanie - (Convolution filters for edge enhancement)\n",
    "4. Resizing - vsetky snimky budeme skalovat do rovnakych rozmerov (224x224px) zachováva jednotnosť nižšie \"rozšírených\" obrázkov. \n",
    "5. Data Augmentation - obrazky budeme horizontalne otáčať, keďže vertikálne by nebolo vhodné keďže ide o ľudské plúca a výskit srdca na snímke by mohlo poškodiť/ovplyvniť trénovanie modelu\n",
    "6. Binarizácia\n",
    "7. Normalizacia pixelov - pre kazdu snimku normalizujeme pixely na hodnoty medzi [0,1] alebo [-1, 1]\n",
    "\n",
    "Následujúce poradie by sme mohli ešte trocha zmeniť, ako napríklad performovať resizing ako prvý. Potom by sa ostatne techniky robili na značne menších rozmeroch a teda by sa čas vykonanie preprocessingu značne znížil, no kvalita niektorých procesov by sa mohla znížiť. V prvom pokuse necháme teda toto poradie a prípadne ho zmenime ak narazíme na problem s výpočtovým časom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Grayscaling (Hotový v EDA časti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Redukcia šumu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def reduce_noise(image):\n",
    "    if isinstance(image, Image.Image):\n",
    "        image = np.array(image)\n",
    "    denoised_image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    return denoised_image\n",
    "\n",
    "# Example before/after\n",
    "normal_image_path = Path(\"Covid_preprocess/train/Normal/020.jpg\")\n",
    "original_image = Image.open(normal_image_path)\n",
    "\n",
    "# BEFORE: Convert to numpy array for consistency\n",
    "original_image_np = np.array(original_image)\n",
    "\n",
    "# Apply noise reduction\n",
    "denoised_image = reduce_noise(original_image)\n",
    "\n",
    "# Plot side by side\n",
    "plt.figure(figsize=(5, 3))\n",
    "\n",
    "# Original image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(original_image_np, cmap='gray')\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Denoised image\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(denoised_image, cmap='gray')\n",
    "plt.title(\"Denoised Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Zaostrovanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpen_image(image):\n",
    "    \n",
    "    if isinstance(image, Image.Image):\n",
    "        image = np.array(image)\n",
    "    kernel = np.array([[0, -1, 0], \n",
    "                       [-1, 5, -1], \n",
    "                       [0, -1, 0]])\n",
    "    sharpened_image = cv2.filter2D(image, -1, kernel)\n",
    "    return sharpened_image\n",
    "\n",
    "# Example before/after\n",
    "sharpened_image = sharpen_image(original_image)\n",
    "\n",
    "# Plot side by side\n",
    "plt.figure(figsize=(5, 3))\n",
    "\n",
    "# Original image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(original_image_np, cmap='gray')\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Denoised image\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(sharpened_image, cmap='gray')\n",
    "plt.title(\"Sharpened Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Resizing (224x224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def resize_image(image, output_size=(224, 224)):\n",
    "    return image.resize(output_size)\n",
    "\n",
    "# Example before/after\n",
    "original_image_np = np.array(original_image)\n",
    "\n",
    "# Resize image\n",
    "resized_image = resize_image(original_image)\n",
    "\n",
    "# Plot side by side\n",
    "plt.figure(figsize=(5, 3))\n",
    "\n",
    "# Original image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(original_image_np, cmap='gray' if original_image.mode == \"L\" else None)\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Resized image\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(np.array(resized_image), cmap='gray' if resized_image.mode == \"L\" else None)\n",
    "plt.title(\"Resized Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Augmentation (horizontal flipping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def augment_image(image):\n",
    "    if not isinstance(image, Image.Image):\n",
    "        image = Image.fromarray(image)\n",
    "    if random.choice([True, False]):\n",
    "        image = image.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "    return image\n",
    "\n",
    "# Example before/after\n",
    "augmented_image = augment_image(original_image)\n",
    "\n",
    "# Plot side by side\n",
    "plt.figure(figsize=(5, 3))\n",
    "\n",
    "# Original image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(original_image_np, cmap='gray')\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Denoised image\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(augmented_image, cmap='gray')\n",
    "plt.title(\"Augmented Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Binarizácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_image(image, threshold=128):\n",
    "    if isinstance(image, Image.Image):\n",
    "        if image.mode != \"L\":\n",
    "            image = image.convert(\"L\") # ensure grayscale\n",
    "        image = np.array(image)\n",
    "    _, binarized_image = cv2.threshold(image, threshold, 255, cv2.THRESH_BINARY)\n",
    "    return binarized_image\n",
    "\n",
    "original_image_np = np.array(original_image)\n",
    "\n",
    "# Apply binarization\n",
    "binarized_image = binarize_image(original_image)\n",
    "\n",
    "# Plot side by side\n",
    "plt.figure(figsize=(5, 3))\n",
    "\n",
    "# Original image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(original_image_np, cmap='gray' if original_image.mode == \"L\" else None)\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Binarized image\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(binarized_image, cmap='gray')\n",
    "plt.title(\"Binarized Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Normalizácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    if isinstance(image, Image.Image):\n",
    "        image = np.array(image)\n",
    "    normalized_image = image / 255.0\n",
    "    return normalized_image\n",
    "\n",
    "# Example usage\n",
    "normalized_image = normalize_image(binarized_image)\n",
    "print(normalized_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "toto boli samostatne metody, my ale chceme tieto metody spolocne vyuzit takze si vytvorime jednoduchu pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_resize_first(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = resize_image(image)\n",
    "    image = reduce_noise(image)\n",
    "    image = sharpen_image(image)\n",
    "    image = augment_image(image)\n",
    "    image = binarize_image(image)\n",
    "    # image = normalize_image(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "image_path = \"Covid_preprocess/train/Normal/020.jpg\"\n",
    "preprocessed_image = preprocess_image_resize_first(image_path)\n",
    "\n",
    "# Display preprocessed image\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.imshow(preprocessed_image, cmap='gray')\n",
    "plt.title(\"Preprocessed Image Resize First\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_resize_trd(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = reduce_noise(np.array(image))\n",
    "    image = sharpen_image(image)\n",
    "    image = resize_image(Image.fromarray(image))\n",
    "    # image = augment_image(image)\n",
    "    # image = binarize_image(image)\n",
    "    image = normalize_image(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "image_path = \"Covid_preprocess/train/Normal/020.jpg\"\n",
    "preprocessed_image = preprocess_image_resize_trd(image_path)\n",
    "\n",
    "# Display preprocessed image\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.imshow(preprocessed_image, cmap='gray')\n",
    "plt.title(\"Preprocessed Image Resize later\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zaver Preprocessingu\n",
    "V zavere preprocessingu mozme vidiet ze pipeline v ktorej resizujeme snimky neskor zachovavaju viac detailov a nie su skoro takmer viac casovo narocnejsie na vykonanie preto pouzijeme na preprocessing vsetkych trenovacich aj testovacich dat tuto pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nasledujuci kod sa bude vyuzivat na dynamicke priame preprocesovanie dat pomocou \n",
    "# pipeline bez ukladania preprocesovanych dat na disk ale iba v premennych\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def create_dataset(data_dir, label_map):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Iterate through class subdirectories\n",
    "    for class_name, label in label_map.items():\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        for image_name in os.listdir(class_dir):\n",
    "            image_path = os.path.join(class_dir, image_name)\n",
    "            try:\n",
    "                # Preprocess image\n",
    "                preprocessed_image = preprocess_image_resize_trd(image_path)\n",
    "                X.append(preprocessed_image)\n",
    "                y.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_name}: {e}\")\n",
    "\n",
    "    # Convert lists to NumPy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Shuffle the dataset while keeping images and labels aligned\n",
    "    indices = np.arange(len(X))  # Create an array of indices\n",
    "    np.random.shuffle(indices)  # Shuffle the indices\n",
    "    X = X[indices]  # Apply the shuffled indices to X\n",
    "    y = y[indices]  # Apply the same shuffled indices to y\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage on ALL Training data\n",
    "train_data_dir = \"Covid_preprocess/train\"\n",
    "label_map = {\"Covid\": 0, \"Normal\": 1, \"Viral Pneumonia\": 2}\n",
    "\n",
    "X_train, y_train = create_dataset(train_data_dir, label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage on ALL Test data\n",
    "test_data_dir = \"Covid_preprocess/test\"\n",
    "\n",
    "X_test, y_test = create_dataset(test_data_dir, label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este overime aku strukturu maju ulozene data predtym ako to budeme pasovat do modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape\n",
    "# (312, 224, 224) -> mame 312 snimkov v rozmeroch 224x224\n",
    "# nemame 4. dimenziu kde by normalne boli RGB kanaly, \n",
    "# pretoze po preprocessingu mame vsetky snimky v grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0] # mozme vidiet ze data su normalizovane medzi (0 a 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape\n",
    "# (312,) -> mame 312 zakodovanych lables\n",
    "# label_map = {\"Covid\": 0, \"Normal\": 1, \"Viral Pneumonia\": 2}\n",
    "# hodnota v arrayi y_train zodpoveda labelu ktory je namapovany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map_reverse = {0:\"Covid\", 1:\"Normal\", 2:\"Viral Pneumonia\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definujeme funkciu ktora zobrazi preprocesnuty image aj s nazvom\n",
    "\n",
    "def plot_sample(X, y, index):\n",
    "    plt.figure(figsize=(15,2))\n",
    "    plt.imshow(X[index], cmap=\"gray\")\n",
    "    plt.xlabel(label_map_reverse[y[index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample(X_train, y_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (B-1b)\tZdôvodnite výber ML/DL metód vzhľadom na Vami vybraný dataset pre 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Modeling and evaluation (5b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (A-4b)\tModeluje Vami tie vybrané charakteristiky pomocou vhodných ML/DL\tmetód. Výsledok modelovania je najlepší model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zacneme basic jednoduchym modelom\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "ann = models.Sequential([\n",
    "    layers.Flatten(input_shape=(224, 224, 1)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "ann.compile(optimizer='SGD',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "ann.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "y_pred = ann.predict(X_test)\n",
    "y_pred_classes = [np.argmax(elem) for elem in y_pred]\n",
    "\n",
    "print(\"classific report: \\n\", classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Iteracia CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = models.Sequential([\n",
    "    # cnn\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(224, 224, 1)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', input_shape=(224, 224, 1)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    #dense\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "cnn.compile(optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "history = cnn.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = cnn.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Po 1. Iteracii CNN\n",
    "po trenovani 1. cnn modelu mozme vidiet 100% accuracy na testovacich datach co \"smrdi\" overfitom, preto vyskusame najskor pridanie dropoutov, ktore urcite neurony s danou pravdepodobnostou \"vypnu\" tymto sa znizi sanca overfitu "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Iteracia CNN (pridanie dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = models.Sequential([\n",
    "    # cnn\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(224, 224, 1)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "\n",
    "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', input_shape=(224, 224, 1)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "\n",
    "    #dense\n",
    "    layers.Flatten(),\n",
    "\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "cnn.compile(optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "history = cnn.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = cnn.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract training and validation loss from history\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "# Plot Training and Validation Loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, train_loss, label='Training Loss', marker='o')\n",
    "plt.plot(epochs, val_loss, label='Validation Loss', marker='x')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Po 2. Iteracii CNN\n",
    "na vysledkoch mozme vidiet znizenie accuracy na train aj test datach co znaci znizenie alebo eliminovanie overfitu. Mozme taktiez na grafoch pozorovat znizujuce sa loss funkcie a teda vidime ze by nemalo dochadzat k overfittingu pri 5 epochoch a tomto nastaveni modela\n",
    "\n",
    "V 3. iteracii pouzijeme crossvalidation a hyperparameter tuning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Iteracia CNN (crossvalidation a tuning)\n",
    "\n",
    "rozhodli sme sa nahadzat nejake parametre pre tuning\n",
    "\n",
    "```py\n",
    "param_grid = {\n",
    "    'learning_rate': [0.005, 0.001, 0.0005],\n",
    "    'dropout_rate': [0, 0.25, 0.3, 0.5],\n",
    "    'dense_units': [32, 64, 128],\n",
    "    'convolution_filters': [32, 64, 128]\n",
    "}\n",
    "```\n",
    "\n",
    "pre toto by ale gridsearch trval az moc dlho pre pravdepodobne este nie dokonale vysledky, skratka by sa to nevyplatilo, preto sme sa rozhodli pouzit Bayesian Optimization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import KFold, ParameterGrid\n",
    "# import numpy as np\n",
    "# from tensorflow.keras import models, layers\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# # Hyperparameter grid\n",
    "# param_grid = {\n",
    "#     'learning_rate': [0.005, 0.001, 0.0005],\n",
    "#     'dropout_rate': [0, 0.25, 0.3, 0.5],\n",
    "#     'dense_units': [32, 64, 128],\n",
    "#     'convolution_filters': [32, 64, 128]\n",
    "# }\n",
    "\n",
    "# # Cross-validation setup\n",
    "# k = 5\n",
    "# kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# best_hyperparams = None\n",
    "# best_cv_accuracy = 0\n",
    "# all_losses = {}  # To store loss curves for visualization\n",
    "\n",
    "# for params in ParameterGrid(param_grid):\n",
    "#     fold_accuracies = []\n",
    "#     fold_losses = {'train_loss': [], 'val_loss': []}\n",
    "    \n",
    "#     for fold, (train_index, val_index) in enumerate(kf.split(X_train), start=1):\n",
    "#         # Train-validation split for this fold\n",
    "#         X_fold_train, X_fold_val = X_train[train_index], X_train[val_index]\n",
    "#         y_fold_train, y_fold_val = y_train[train_index], y_train[val_index]\n",
    "        \n",
    "#         # Define the CNN model\n",
    "#         cnn = models.Sequential([\n",
    "#             layers.Conv2D(16, (3, 3), activation='relu', input_shape=(224, 224, 1)),\n",
    "#             layers.MaxPooling2D((2, 2)),\n",
    "#             layers.Dropout(params['dropout_rate']),\n",
    "            \n",
    "#             layers.Conv2D(params['convolution_filters'], (3, 3), activation='relu'),\n",
    "#             layers.MaxPooling2D((2, 2)),\n",
    "#             layers.Dropout(params['dropout_rate']),\n",
    "            \n",
    "#             layers.Flatten(),\n",
    "#             layers.Dense(params['dense_units'], activation='relu'),\n",
    "#             layers.Dropout(params['dropout_rate']),\n",
    "#             layers.Dense(3, activation='softmax')\n",
    "#         ])\n",
    "        \n",
    "#         cnn.compile(optimizer=Adam(learning_rate=params['learning_rate']),\n",
    "#                     loss='sparse_categorical_crossentropy',\n",
    "#                     metrics=['accuracy'])\n",
    "        \n",
    "#         # Train the model and track history\n",
    "#         history = cnn.fit(X_fold_train, y_fold_train, epochs=5, verbose=0, validation_data=(X_fold_val, y_fold_val))\n",
    "        \n",
    "#         # Record training and validation losses for this fold\n",
    "#         fold_losses['train_loss'].append(history.history['loss'])\n",
    "#         fold_losses['val_loss'].append(history.history['val_loss'])\n",
    "        \n",
    "#         # Evaluate on the validation set\n",
    "#         val_loss, val_accuracy = cnn.evaluate(X_fold_val, y_fold_val, verbose=0)\n",
    "#         fold_accuracies.append(val_accuracy)\n",
    "    \n",
    "#     # Average accuracy across folds for this parameter set\n",
    "#     mean_cv_accuracy = np.mean(fold_accuracies)\n",
    "#     print(f\"Params: {params}, Mean CV Accuracy: {mean_cv_accuracy}\")\n",
    "    \n",
    "#     # Save the losses for this parameter set\n",
    "#     all_losses[str(params)] = fold_losses\n",
    "    \n",
    "#     # Update the best hyperparameters if current accuracy is better\n",
    "#     if mean_cv_accuracy > best_cv_accuracy:\n",
    "#         best_cv_accuracy = mean_cv_accuracy\n",
    "#         best_hyperparams = params\n",
    "\n",
    "# print(f\"Best Hyperparameters: {best_hyperparams}, Best CV Accuracy: {best_cv_accuracy}\")\n",
    "\n",
    "# # Visualize loss for the best hyperparameter combination\n",
    "# best_losses = all_losses[str(best_hyperparams)]\n",
    "\n",
    "# # Plot training and validation loss curves\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# for fold in range(k):\n",
    "#     plt.plot(range(1, 6), best_losses['train_loss'][fold], label=f'Fold {fold+1} Train Loss', linestyle='-')\n",
    "#     plt.plot(range(1, 6), best_losses['val_loss'][fold], label=f'Fold {fold+1} Val Loss', linestyle='--')\n",
    "\n",
    "# plt.title('Training and Validation Loss Across Folds for Best Hyperparameters')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Po 3. Iteracii CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (B-1b)\tZhodnotíte Váš prístup a získaný výsledok\t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
